{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3428c86b-4349-44e7-9e35-0706c1517c5a",
   "metadata": {},
   "source": [
    "# Rain rate from IMERG\n",
    "\n",
    "NASA’s Integrated Multi-satellitE Retrievals for GPM [IMERG](https://gpm.nasa.gov/data/imerg) algorithm combines information from the GPM satellite constellation to estimate precipitation over the majority of the Earth's surface. IMERG fuses precipitation estimates collected during the TRMM satellite’s operation (2000 - 2015) with recent precipitation estimates collected by the GPM mission (2014 - present) creating a continuous precipitation dataset spanning over two decades. This extended record allows scientists to compare past and present precipitation trends, enabling more accurate climate and weather models and a better understanding of Earth’s water cycle and extreme precipitation events. IMERG is available in near real-time with estimates of Earth’s precipitation updated every half-hour, enabling a wide range of applications to help communities around the world make informed decisions for disasters, disease, resource management, energy production, food security, and more.\n",
    "\n",
    "## Getting the data\n",
    "I really didn't want to download data for an entire year (more than 100 GB!!!) just to get a single point of data from each file. It was difficult to find the data because I couldn't find out any information on whether it was on the cloud from the IMERG websites that describe the data [https://gpm.nasa.gov/data/directory]. Once I figured out what data product I needed, I went to see if I could find it on the cloud.\n",
    "\n",
    "\n",
    "## NASA's data on AWS cloud\n",
    "\n",
    "I found only [this reference](https://climatedataguide.ucar.edu/climate-data/gpm-global-precipitation-measurement-mission) to the data being on the cloud.\n",
    "\n",
    "Search: 'read imerg data python'  \n",
    "As I was searching for the data on the cloud I came across a number of notebooks that have not aged well. \n",
    "[This](https://github.com/nasa/gesdisc-tutorials/blob/main/notebooks/How_to_Read_IMERG_Data_Using_Python.ipynb) notebook is put out by NASA. It uses the h5py library and makes reading the data much more complicated (and prone to error) than it needed to be. \n",
    "\n",
    "Another [tutorial](https://gpm.nasa.gov/data/tutorials) on the NASA mission website again uses h5py and a shapefile rather than cartopy to plot the data. \n",
    "\n",
    "This was the [notebook](https://github.com/nsidc/NSIDC-Data-Tutorials/blob/main/notebooks/ICESat-2_Cloud_Access/ATL06-direct-access.ipynb) that ended up quickly helping me sort out how to get the data\n",
    "\n",
    "I wasted time by trying to just write a loop that would read the data and concat it onto a time series. It turned out to just be easier to read each day and write out each day's data then put it all together at the end. This was mostly due to the error prone nature of reading data from the cloud from a local computer. It is just better to work one step at a time.\n",
    "\n",
    "# V06 versus V07\n",
    "\n",
    "For 2024, V07 is missing all data in May and therefore V06 data was used. This required changing the variable name in V06 data from 'precipitationCal' to 'precipitation'. IMERG v07 includes a wide range of algorithm changes, including updates to the inputs for IMERG, and a switch to CORRA V07 and GPROF V07. Users are discouraged from mixing data from the two versions because V06 and V07 are sufficiently different. For this visualization, we are mixing the data because there was no other option. V06 data stops on June 1, 2024 and we need data through December 21, 2024.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a4e5e9-64b9-4e4e-9aad-7e7ebf0d98dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Earthdata Login username:  cgentemann\n",
      "Enter your Earthdata password:  ········\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<earthaccess.auth.Auth at 0x12f48b830>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "import requests\n",
    "import boto3\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import earthaccess\n",
    "import datetime\n",
    "import warnings\n",
    "import time\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "salesforce_lat = 37.7899\n",
    "salesforce_lon = -122.3969\n",
    "\n",
    "file_path = '../data/daily/imerg'\n",
    "\n",
    "earthaccess.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fe01ef7-6525-4892-8f31-07bebccb7018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_day(year):\n",
    "    istart=1\n",
    "    ds_ts=[]\n",
    "    for day in range(1,366):\n",
    "        file_output_name = file_path+str(year)+str(day)+'.nc'\n",
    "        \n",
    "        if not(os.path.exists(file_output_name)):\n",
    "            istart = day\n",
    "            break\n",
    "    return istart\n",
    "\n",
    "def try_data(results):\n",
    "    max_retries = 20  # Number of retry attempts\n",
    "    ds = []\n",
    "    file_handlers = earthaccess.open(results)\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            ds =  xr.open_mfdataset(file_handlers, group=\"Grid\", combine='by_coords')\n",
    "            print(\"Successfully opened\",day)\n",
    "            break  # Exit the retry loop if successful\n",
    "        except Exception as e:\n",
    "            print(\"Failed to open\",day,attempt)\n",
    "            if attempt < max_retries - 1:  # Check if more attempts are available\n",
    "               time.sleep(10)  # Wait for 5 seconds before retrying\n",
    "            else:\n",
    "               break\n",
    "    return ds\n",
    "\n",
    "def get_day_data(year,day,slat,slon):\n",
    "    date = datetime.date(year, 1, 1) + datetime.timedelta(days=day - 1)\n",
    "    date_str = date.strftime('%Y-%m-%d')\n",
    "    if year == 2023 or (year == 2024 and (day<122 or day>152)): #v07 missing for all of may 2024, switch to v06 for this month\n",
    "        iversion = '07'\n",
    "        results = earthaccess.search_data(short_name='GPM_3IMERGHHL',temporal=(date_str, date_str),version=iversion)  #late run 12 hour lag\n",
    "        ds = try_data(results)\n",
    "        subset = ds.precipitation.sel(lat= slat,lon=slon,method='nearest') \n",
    "    else:\n",
    "        iversion = '06'        \n",
    "        results = earthaccess.search_data(short_name='GPM_3IMERGHHL',temporal=(date_str, date_str),version=iversion)  #late run 12 hour lag\n",
    "        ds = try_data(results)\n",
    "        subset = ds.precipitationCal.sel(lat= slat,lon=slon,method='nearest').rename('precipitation')\n",
    "    ds.close()\n",
    "    subset['time'] = subset.indexes['time'].to_datetimeindex() #change from cftime to dt64\n",
    "    print('read',day,len(subset))\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d111a5e-bdac-4d91-9ed6-e2dd60f1216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde0f9afbd484fdea247b075d1e50498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b54210d2974c9b8380b089d595ee14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8201f788e0df49838acbc04a8641926b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to open 172 0\n",
      "Failed to open 172 1\n",
      "Failed to open 172 2\n",
      "Failed to open 172 3\n",
      "Failed to open 172 4\n",
      "Failed to open 172 5\n",
      "Failed to open 172 6\n",
      "Failed to open 172 7\n",
      "Failed to open 172 8\n",
      "Failed to open 172 9\n",
      "Failed to open 172 10\n",
      "Failed to open 172 11\n",
      "Failed to open 172 12\n",
      "Failed to open 172 13\n",
      "Failed to open 172 14\n",
      "Failed to open 172 15\n",
      "Failed to open 172 16\n",
      "Failed to open 172 17\n",
      "Failed to open 172 18\n",
      "Failed to open 172 19\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'precipitation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m day \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(istart_day, \u001b[38;5;241m280\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarting\u001b[39m\u001b[38;5;124m'\u001b[39m,day)\n\u001b[0;32m----> 7\u001b[0m     ds_ts \u001b[38;5;241m=\u001b[39m \u001b[43mget_day_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43mday\u001b[49m\u001b[43m,\u001b[49m\u001b[43msalesforce_lat\u001b[49m\u001b[43m,\u001b[49m\u001b[43msalesforce_lon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     file_output_name \u001b[38;5;241m=\u001b[39m file_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(year)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(day)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m     ds_ts\u001b[38;5;241m.\u001b[39mto_netcdf(file_output_name)\n",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m, in \u001b[0;36mget_day_data\u001b[0;34m(year, day, slat, slon)\u001b[0m\n\u001b[1;32m     34\u001b[0m     results \u001b[38;5;241m=\u001b[39m earthaccess\u001b[38;5;241m.\u001b[39msearch_data(short_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPM_3IMERGHHL\u001b[39m\u001b[38;5;124m'\u001b[39m,temporal\u001b[38;5;241m=\u001b[39m(date_str, date_str),version\u001b[38;5;241m=\u001b[39miversion)  \u001b[38;5;66;03m#late run 12 hour lag\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     ds \u001b[38;5;241m=\u001b[39m try_data(results)\n\u001b[0;32m---> 36\u001b[0m     subset \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecipitation\u001b[49m\u001b[38;5;241m.\u001b[39msel(lat\u001b[38;5;241m=\u001b[39m slat,lon\u001b[38;5;241m=\u001b[39mslon,method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     iversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m06\u001b[39m\u001b[38;5;124m'\u001b[39m        \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'precipitation'"
     ]
    }
   ],
   "source": [
    "# Read data on cloud and put into daily files\n",
    "year=2023\n",
    "istart_day = get_start_day(year)\n",
    "istart_day = 172 \n",
    "for day in range(istart_day, 280):\n",
    "    print('starting',day)\n",
    "    ds_ts = get_day_data(year,day,salesforce_lat,salesforce_lon)\n",
    "    file_output_name = file_path+str(year)+str(day)+'.nc'\n",
    "    ds_ts.to_netcdf(file_output_name)\n",
    "    print('output',day,file_output_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
